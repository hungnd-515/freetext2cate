{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "\n",
    "from apiclient import discovery\n",
    "from oauth2client import client\n",
    "from oauth2client import tools\n",
    "import httplib2 \n",
    "\n",
    "from sklearn.datasets.base import Bunch\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from pymongo import MongoClient\n",
    "\n",
    "\n",
    "df = pd.read_csv('1_mil.csv')\n",
    "\n",
    "\n",
    "\n",
    "cate = pd.read_csv('cate.csv')\n",
    "\n",
    "list_lv1 = cate['lv1_eng'].unique().tolist()\n",
    "cate['lv1_label'] = 0\n",
    "cate['lv2_label'] = 0\n",
    "u = 1\n",
    "for lv1 in list_lv1:\n",
    "    cate.loc[cate['lv1_eng']==lv1,['lv1_label']] = u\n",
    "    list_lv2 = cate[cate['lv1_eng']==lv1]['lv2_eng'].unique().tolist()\n",
    "    v = 1\n",
    "    for lv2 in list_lv2:\n",
    "        cate.loc[cate['lv2_eng']==lv2,['lv2_label']] = u*100 + v\n",
    "        v += 1\n",
    "    u += 1\n",
    "    \n",
    "\n",
    "cate['lv1_eng'] = cate['lv1_eng'].apply(lambda x: x.lower())\n",
    "cate['lv2_eng'] = cate['lv2_eng'].apply(lambda x: x.lower())\n",
    "\n",
    "df.head()\n",
    "\n",
    "df.drop(columns=['level_2','lv3','Pic',''],inplace=True)\n",
    "\n",
    "df.columns = ['keyword','lv1_1','lv1_2','lv1_3','lv2_1','lv2_2','lv2_3','lv2_4']\n",
    "\n",
    "for col in df.columns.tolist():\n",
    "    df[col] = df[col].apply(lambda x: x.lower() if x != None else None)\n",
    "    df[col] = df[col].apply(lambda x: None if x == '' else x)\n",
    "\n",
    "df.loc[(df['lv2_3'].isna()==True)&(df['lv2_4'].isna()==False),['lv2_3']] = df['lv2_4']\n",
    "df.loc[(df['lv2_2'].isna()==True)&(df['lv2_3'].isna()==False),['lv2_2']] = df['lv2_3']\n",
    "df.loc[(df['lv2_1'].isna()==True)&(df['lv2_2'].isna()==False),['lv2_1']] = df['lv2_2']\n",
    "\n",
    "\n",
    "df.loc[((df['lv1_2'].isna()==True)|(df['lv1_2']=='other'))&(df['lv1_3'].isna()==False),['lv1_2']] = df['lv1_3']\n",
    "df.loc[((df['lv1_1'].isna()==True)|(df['lv1_1']=='other'))&(df['lv1_2'].isna()==False),['lv1_1']] = df['lv1_2']\n",
    "\n",
    "cate_dict = cate[['lv2_eng','lv2_label']].set_index(keys='lv2_label').to_dict(orient='dict')['lv2_eng']\n",
    "\n",
    "# cate_dict = {}\n",
    "# for i in range(len(cate)):\n",
    "    \n",
    "\n",
    "cate_dict_lv1_2_lv2 = {lv1:cate[cate['lv1_eng']==lv1]['lv2_eng'].tolist() for lv1 in cate['lv1_eng'].tolist()}\n",
    "\n",
    "cate_dict_lv2_2_lv1 = {lv2:cate[cate['lv2_eng']==lv2]['lv1_eng'].tolist()[0] for lv2 in cate['lv2_eng'].tolist()}\n",
    "\n",
    "\n",
    "\n",
    "df['lv2_label'] = df['lv2_1'].apply(lambda x: cate[cate['lv2_eng']==x]['lv2_label'].tolist()[0] if len(cate[cate['lv2_eng']==x]['lv2_label'].tolist()) > 0  else 0)\n",
    "\n",
    "mil = pd.read_csv('1_mil.csv')\n",
    "\n",
    "mil.dropna(inplace=True)\n",
    "\n",
    "mil['aha_cate'] = mil['aha_cate'].apply(lambda x: x.lower())\n",
    "\n",
    "cate_dict_rev = cate[['lv2_eng','lv2_label']].set_index(keys='lv2_eng').to_dict(orient='dict')['lv2_label']\n",
    "\n",
    "mil['lv2_label'] = mil['aha_cate'].apply(lambda x: cate_dict_rev[x])\n",
    "\n",
    "mil.head()\n",
    "\n",
    "df.rename(columns = {'keyword':'name'},inplace=True)\n",
    "\n",
    "df_data = pd.concat([mil[['name','lv2_label']],df[['name','lv2_label']]])\n",
    "\n",
    "df_data.reset_index(drop=True,inplace=True)\n",
    "\n",
    "items = []\n",
    "for i in range(len(df_data)):\n",
    "    items += [{\"keyword\":df_data.loc[i]['name'],\"label\":df_data.loc[i]['lv2_label']}]\n",
    "\n",
    "# a = df['lv2_1'].unique().tolist()\n",
    "\n",
    "# b = cate['lv2_eng'].unique().tolist()\n",
    "\n",
    "# b\n",
    "\n",
    "# for i in a:\n",
    "#     if i not in b:\n",
    "#         print(i)\n",
    "\n",
    "# [x.lower() for x in df.columns.tolist()]\n",
    "\n",
    "# Get training data\n",
    "data = []\n",
    "target = []\n",
    "for item in items:\n",
    "    data.append(item[\"keyword\"].lower())\n",
    "    target.append(item[\"label\"])\n",
    "train = Bunch(data=data, target=target)\n",
    "\n",
    "# Build Text classification model\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, n_iter=5, random_state=42)),\n",
    "                     ])\n",
    "text_clf = text_clf.fit(train.data, train.target)\n",
    "\n",
    "\n",
    "\n",
    "# import gdown\n",
    "# file_id = '1--yNhXLC3_YHg8ctMiFN_lu1NzakkmZD'\n",
    "# output = '1_mil.csv' #name of output file after download\n",
    "# url = 'https://drive.google.com/uc?id='+file_id\n",
    "# gdown.download(url ,output,quiet=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = input()\n",
    "cate_dict.get(text_clf.predict([a])[0])"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
